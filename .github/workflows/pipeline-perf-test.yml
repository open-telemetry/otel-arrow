name: Pipeline Performance Tests
permissions:
  contents: read

on:
    push:
        branches: [ main ]
    workflow_dispatch:

# Cancel in-progress runs on new commits to same PR
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
    pipeline-perf-test:
        runs-on: ubuntu-24.04
        steps:
        - name: Harden the runner (Audit all outbound calls)
          uses: step-security/harden-runner@c6295a65d1254861815972266d5933fd6e532bdf # v2.11.1
          with:
            egress-policy: audit

        - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

        - name: Set up Python
          uses: actions/setup-python@7f4fc3e22c37d6ff65e88745f38bd3157c663f7c # v4.9.1
          with:
            python-version: '3.13'
            cache: 'pip'

        - name: Install dependencies
          run: |
            python -m pip install --upgrade pip
            pip install -r tools/pipeline_perf_test/orchestrator/requirements.txt
            pip install -r tools/pipeline_perf_test/load_generator/requirements.txt

        - name: Run pipeline performance test with default configuration
          run: |
            cd tools/pipeline_perf_test
            python orchestrator/orchestrator.py --collector-config system_under_test/otel-collector/collector-config.yaml --duration 30 --results-dir ./results/default

        - name: Run pipeline performance test with batch processor configuration
          run: |
            cd tools/pipeline_perf_test
            python orchestrator/orchestrator.py --collector-config system_under_test/otel-collector/collector-config-with-batch-processor.yaml --duration 30 --results-dir ./results/batch-processor

        - name: Upload benchmark results for processing
          uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
          with:
            name: benchmark-results-pipeline
            path: tools/pipeline_perf_test/results/*/benchmark_*.json

    update-benchmarks:
        runs-on: ubuntu-24.04
        needs: [pipeline-perf-test]
        permissions:
          # deployments permission to deploy GitHub pages website
          deployments: write
          # contents permission to update benchmark contents in gh-pages branch
          contents: write
        steps:
          - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

          - name: Download benchmark artifacts
            uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
            with:
              pattern: benchmark-results-*
              merge-multiple: true
              path: results

          - name: Consolidate benchmark data
            run: |
              echo "Consolidating benchmark JSON files..."
              find results -name "benchmark_*.json" -type f | while read file; do
                echo "Processing: $file"
                cat "$file"
                echo
              done

              # Combine all benchmark JSON files into a single output (find them recursively)
              find results -name "benchmark_*.json" -type f -exec cat {} \; | jq -s 'map(.[])' > output.json

              echo "Consolidated benchmark data:"
              cat output.json

          - name: Update benchmark data and deploy to GitHub Pages
            uses: benchmark-action/github-action-benchmark@d48d326b4ca9ba73ca0cd0d59f108f9e02a381c7 # v1.20.4
            with:
              tool: "customSmallerIsBetter"
              output-file-path: output.json
              gh-pages-branch: benchmarks
              max-items-in-chart: 100
              github-token: ${{ secrets.GITHUB_TOKEN }}
              benchmark-data-dir-path: "docs/benchmarks/pipeline-perf"
              auto-push: true
              save-data-file: true
