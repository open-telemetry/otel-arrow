name: Pipeline Performance Tests - Continuous
permissions:
  contents: read

on:
    push:
        branches: [ main ]
    workflow_dispatch:

# Cancel in-progress runs on new commits to same PR
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
    pipeline-perf-test:
        runs-on: oracle-bare-metal-64cpu-512gb-x86-64
        steps:
        - name: Harden the runner (Audit all outbound calls)
          uses: step-security/harden-runner@95d9a5deda9de15063e7595e9719c11c38c90ae2 # v2.13.2
          with:
            egress-policy: audit

        - uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1

        - id: detect_os
          name: Detect OS (self-hosted)
          shell: bash
          run: |
            . /etc/os-release
            echo "id=$ID" >> "$GITHUB_OUTPUT"
            echo "version_id=$VERSION_ID" >> "$GITHUB_OUTPUT"

        - name: Install/prepare Python 3.11 on Oracle Linux 8 (self-hosted only)
          if: ${{ runner.os == 'Linux' && steps.detect_os.outputs.id == 'ol' && startsWith(steps.detect_os.outputs.version_id, '8') }}
          shell: bash
          run: |
            set -euxo pipefail

            # Run disk cleanup script
            bash ./.github/workflows/scripts/disk-cleanup.sh

            # Check if Python 3.11 is already installed to avoid unnecessary dnf operations
            if rpm -q python3.11 python3.11-devel &>/dev/null; then
              echo "Python 3.11 packages already installed, skipping repository setup and package installation"
            else
              # Enable repos and refresh metadata (only runs if Python not installed)
              sudo dnf -y install oracle-epel-release-el8 || true
              sudo dnf -y config-manager --set-enabled ol8_codeready_builder || true
              sudo dnf -y makecache --timer

              # Install core packages (ignore subpackages that don't exist on OL8)
              sudo dnf -y install python3.11 python3.11-devel || true
            fi

            # pip may be packaged as part of python3.11 or available via ensurepip;
            # fall back to ensurepip if needed.
            if ! /usr/bin/python3.11 -m pip --version >/dev/null 2>&1; then
              /usr/bin/python3.11 -m ensurepip --upgrade || true
            fi

            # Only upgrade pip/setuptools/wheel if outdated (skip if already at latest)
            /usr/bin/python3.11 -m pip install --upgrade --upgrade-strategy only-if-needed pip setuptools wheel || true

            # Add a 'python' shim so subsequent steps can call `python ...`
            mkdir -p "$HOME/.local/bin"
            ln -sf /usr/bin/python3.11 "$HOME/.local/bin/python"
            echo "$HOME/.local/bin" >> "$GITHUB_PATH"

            # Smoke test
            python --version
            python -m pip --version

        - name: Build dataflow_engine
          run: |
            git submodule init
            git submodule update
            cd rust/otap-dataflow
            docker build --build-context otel-arrow=../../ -f Dockerfile -t df_engine .
            cd ../..

        - name: Install dependencies
          run: |
            python -m pip install --user --upgrade pip
            pip install --user -r tools/pipeline_perf_test/orchestrator/requirements.txt
            pip install --user -r tools/pipeline_perf_test/load_generator/requirements.txt

        - name: Run pipeline performance test log suite
          run: |
            cd tools/pipeline_perf_test
            python orchestrator/run_orchestrator.py --debug --config test_suites/integration/continuous/100klrps-docker.yaml

        - name: Run pipeline performance test log suite - Saturation
          run: |
            cd tools/pipeline_perf_test
            python orchestrator/run_orchestrator.py --debug --config test_suites/integration/continuous/saturation-docker.yaml

        - name: Upload benchmark results for processing
          uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
          with:
            name: benchmark-results-pipeline
            path: tools/pipeline_perf_test/results/integration/gh-actions-benchmark/*.json

        - name: Upload benchmark results for processing (Saturation)
          uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
          with:
            name: benchmark-results-saturation
            path: tools/pipeline_perf_test/results/continuous_saturation/gh-actions-benchmark/*.json

        - name: Add benchmark link to job summary
          run: |
            echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
            echo "[View the benchmark results here](https://open-telemetry.github.io/otel-arrow/benchmarks/continuous/)" >> $GITHUB_STEP_SUMMARY

    update-benchmarks:
        runs-on: ubuntu-24.04
        needs: [pipeline-perf-test]
        permissions:
          # deployments permission to deploy GitHub pages website
          deployments: write
          # contents permission to update benchmark contents in gh-pages branch
          contents: write
        steps:
          - uses: actions/checkout@93cb6efe18208431cddfb8368fd83d5badbf9bfd # v5.0.1

          - name: Download benchmark artifacts
            uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0
            with:
              pattern: benchmark-results-pipeline*
              merge-multiple: true
              path: results-pipeline

          - name: Download benchmark artifacts (Saturation)
            uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0
            with:
              pattern: benchmark-results-saturation*
              merge-multiple: true
              path: results-saturation

          - name: Consolidate pipeline benchmark data
            run: |
              echo "Consolidating pipeline benchmark JSON files..."
              find results-pipeline -name "*.json" -type f | while read file; do
                echo "Processing: $file"
                cat "$file"
                echo
              done

              # Combine all benchmark JSON files into a single output (find them recursively)
              find results-pipeline -name "*.json" -type f -exec cat {} \; | jq -s 'map(.[])' > output-pipeline.json

              echo "Consolidated pipeline benchmark data:"
              cat output-pipeline.json

          - name: Consolidate saturation benchmark data
            run: |
              echo "Consolidating saturation benchmark JSON files..."
              find results-saturation -name "*.json" -type f | while read file; do
                echo "Processing: $file"
                cat "$file"
                echo
              done

              # Combine all benchmark JSON files into a single output (find them recursively)
              find results-saturation -name "*.json" -type f -exec cat {} \; | jq -s 'map(.[])' > output-saturation.json

              echo "Consolidated saturation benchmark data:"
              cat output-saturation.json

          - name: Update pipeline benchmark data and deploy to GitHub Pages
            uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1.20.7
            with:
              tool: "customSmallerIsBetter"
              output-file-path: output-pipeline.json
              gh-pages-branch: benchmarks
              max-items-in-chart: 100
              github-token: ${{ secrets.GITHUB_TOKEN }}
              benchmark-data-dir-path: "docs/benchmarks/continuous"
              auto-push: true
              save-data-file: true

          - name: Update saturation benchmark data and deploy to GitHub Pages
            uses: benchmark-action/github-action-benchmark@4bdcce38c94cec68da58d012ac24b7b1155efe8b # v1.20.7
            with:
              tool: "customSmallerIsBetter"
              output-file-path: output-saturation.json
              gh-pages-branch: benchmarks
              max-items-in-chart: 100
              github-token: ${{ secrets.GITHUB_TOKEN }}
              benchmark-data-dir-path: "docs/benchmarks/continuous-saturation"
              auto-push: true
              save-data-file: true

          - name: Add benchmark link to job summary
            run: |
              echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
              echo "[View the pipeline benchmark results here](https://open-telemetry.github.io/otel-arrow/benchmarks/continuous/)" >> $GITHUB_STEP_SUMMARY
              echo "[View the saturation benchmark results here](https://open-telemetry.github.io/otel-arrow/benchmarks/continuous-saturation/)" >> $GITHUB_STEP_SUMMARY
