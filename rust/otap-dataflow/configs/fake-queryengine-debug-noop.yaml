settings:
  default_pipeline_ctrl_msg_channel_size: 100
  default_node_ctrl_msg_channel_size: 100
  default_pdata_channel_size: 100

nodes:
  receiver:
    kind: receiver
    plugin_urn: "urn:otel:otap:fake_data_generator:receiver"
    out_ports:
      out_port:
        destinations:
          - debug1
        dispatch_strategy: round_robin
    config:
      traffic_config:
        max_signal_count: 10000
        max_batch_size: 100
        signals_per_second: 100
        log_weight: 100
      registry_path: https://github.com/open-telemetry/semantic-conventions.git[model]
  debug1:
    kind: processor
    plugin_urn: "urn:otel:debug:processor"
    out_ports:
      out_port:
        destinations:
          - query_engine
        dispatch_strategy: round_robin
    config:
      verbosity: detailed
      output: /tmp/debug1.log
  query_engine:
    kind: processor
    plugin_urn: urn:otel:queryengine:processor
    out_ports:
      out_port:
        destinations:
        - debug2
        dispatch_strategy: round_robin
    config:
      query: logs | where event_name == "gen_ai.system.message"
  debug2:
      kind: processor
      plugin_urn: "urn:otel:debug:processor"
      out_ports:
        out_port:
          destinations:
            - noop
          dispatch_strategy: round_robin
      config:
        verbosity: detailed
        output: /tmp/debug2.log
  noop:
    kind: exporter
    plugin_urn: "urn:otel:noop:exporter"
    config:
