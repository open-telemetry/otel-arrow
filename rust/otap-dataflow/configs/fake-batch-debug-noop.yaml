# Shows the batch processor.
settings:
  default_pipeline_ctrl_msg_channel_size: 100
  default_node_ctrl_msg_channel_size: 100
  default_pdata_channel_size: 100

nodes:
  receiver:
    kind: receiver
    plugin_urn: "urn:otel:otap:fake_data_generator:receiver"
    out_ports:
      out_port:
        destinations:
          - batch
        dispatch_strategy: round_robin
    config:
      traffic_config:
        max_signal_count: 10000
        max_batch_size: 100
        signals_per_second: 100
        log_weight: 100
      registry_path: https://github.com/open-telemetry/semantic-conventions.git[model]
  batch:
    kind: processor
    plugin_urn: "urn:otel:batch:processor"
    out_ports:
      out_port:
        destinations:
          - debug
        dispatch_strategy: round_robin
    config:
      otap:
        # At the rate set above (100/s), min_size=1000 would emit a batch
        # every 10 seconds.
        min_size: 1000
        sizer: items
      # The timeout causes 100/s, so we produce around 300 signals/batch.
      flush_timeout: 3s
  debug:
    kind: processor
    plugin_urn: "urn:otel:debug:processor"
    out_ports:
      out_port:
        destinations:
          - noop
        dispatch_strategy: round_robin
    config:
      verbosity: detailed
      mode: signal
  noop:
    kind: exporter
    plugin_urn: "urn:otel:noop:exporterX"
    config:

service:
  telemetry:
    logs:
      # The default level is "info".
      level: "debug"
      strategies:
        global: raw
        engine: raw
      output: noop
