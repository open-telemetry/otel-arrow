# Fake Data -> Durable Buffer -> Noop pipeline for throughput testing
#
# This configuration uses the fake data generator to produce synthetic OTAP data,
# persists it through Quiver, and sends to noop exporter.
#
# Build with: cargo build --release
# Run with:   ./target/release/df_engine --pipeline configs/fake-durable-buffer-noop.yaml

settings:
  default_pipeline_ctrl_msg_channel_size: 100
  default_node_ctrl_msg_channel_size: 100
  default_pdata_channel_size: 100

nodes:
  receiver:
    type: traffic_generator:receiver
    config:
      traffic_config:
        # Generate signals continuously (null = unlimited)
        max_signal_count: null
        # Batch size of 100 signals per message
        max_batch_size: 100
        # Rate: 10000 signals/sec for sustainable throughput testing
        signals_per_second: 10000
        # Only generate logs (100% weight to logs)
        log_weight: 100

  durable_buffer:
    type: durable_buffer:processor
    config:
      path: /var/lib/otap/fake-durable-buffer-noop-example/buffer
      poll_interval: 10ms
      retention_size_cap: "500MB"
      size_cap_policy: backpressure
      # Faster segment finalization for testing
      max_segment_open_duration: 500ms

  noop:
    type: noop:exporter
    config:

connections:
  - from: receiver
    to: durable_buffer
  - from: durable_buffer
    to: noop
