# OTLP -> Store-and-Forward -> OTLP pipeline example
#
# This configuration demonstrates the store and forward providing
# durable buffering for OTLP data. By default, OTLP bytes are stored as
# opaque binary for efficient pass-through (near-zero CPU overhead).
# Set otlp_handling: convert_to_arrow to enable querying on stored data.
#
# Build with: cargo build --release --features persistence
# Run with:   ./target/release/df_engine --pipeline configs/otlp-store-and-forward-otlp.yaml
#
# To test, run a backend OTLP receiver on port 4318, then send OTLP data to port 4317.

settings:
  default_pipeline_ctrl_msg_channel_size: 100
  default_node_ctrl_msg_channel_size: 100
  default_pdata_channel_size: 100

nodes:
  receiver:
    kind: receiver
    plugin_urn: "urn:otel:otlp:receiver"
    out_ports:
      out_port:
        destinations:
          - store_and_forward
        dispatch_strategy: round_robin
    config:
      listening_addr: "127.0.0.1:4317"

  store_and_forward:
    kind: processor
    plugin_urn: "urn:otel:store_and_forward:processor"
    out_ports:
      out_port:
        destinations:
          - exporter
        dispatch_strategy: round_robin
    config:
      # Directory for WAL and segment files (created if not exists)
      path: ./quiver_data
      # How often to poll Quiver for available bundles (default: 100ms)
      poll_interval: 100ms
      # Maximum age of data to retain (e.g., "24h", "7d")
      max_age: 72h
      # Maximum disk usage for persistence storage
      retention_size_cap: "10GB"
      # What to do when size cap is exceeded: backpressure or drop_oldest
      size_cap_policy: backpressure
      # OTLP handling mode:
      # - pass_through (default): Store OTLP as opaque binary, very CPU efficient
      # - convert_to_arrow: Convert to Arrow format, enables querying but higher CPU
      otlp_handling: pass_through

  exporter:
    kind: exporter
    plugin_urn: "urn:otel:otlp:exporter"
    config:
      grpc_endpoint: "http://127.0.0.1:4318"
